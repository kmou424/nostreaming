# nostreaming

ä¸€ä¸ªé€šç”¨çš„ LLM API åå‘ä»£ç†å·¥å…·ï¼Œæ”¯æŒå¤šä¸ªä¸Šæ¸¸æä¾›å•†ï¼Œæä¾› OpenAI å…¼å®¹çš„æ¥å£ï¼Œå¹¶å®ç°ä¼ªæµå¼ï¼Œè®©ä½ é—²ç½®çš„ç¬¬ä¸‰æ–¹è½¬å‘ API ä¹Ÿèƒ½åˆ©ç”¨èµ·æ¥ã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸ”„ **å¤šæä¾›å•†æ”¯æŒ**: æ”¯æŒ OpenAI ç­‰(å’•å’•å’•)ä¸Šæ¸¸ LLM æä¾›å•†
- ğŸ”Œ **OpenAI å…¼å®¹æ¥å£**: æä¾›æ ‡å‡†çš„ OpenAI API æ¥å£ï¼Œæ— éœ€ä¿®æ”¹å®¢æˆ·ç«¯ä»£ç 
- ğŸ“¡ **Fake-Streaming**: å®ç°ä¼ªæµå¼ä¼ è¾“ï¼Œå®¢æˆ·ç«¯é€šè¿‡ SSE è¿æ¥ï¼Œåç«¯å‘é€éæµå¼è¯·æ±‚åˆ°ä¸Šæ¸¸
- ğŸ” **API å¯†é’¥è®¤è¯**: æ”¯æŒ Bearer token è®¤è¯
- ğŸ¯ **æ¨¡å‹è¿‡æ»¤**: æ”¯æŒç™½åå•/é»‘åå•æ¨¡å¼è¿‡æ»¤æ¨¡å‹
- ğŸ³ **Docker æ”¯æŒ**: æä¾›å®Œæ•´çš„ Docker éƒ¨ç½²æ–¹æ¡ˆ
- ğŸ“Š **ç»“æ„åŒ–æ—¥å¿—**: åŸºäºé…ç½®çš„æ—¥å¿—çº§åˆ«å’Œç»“æ„åŒ–è¾“å‡º

## å¿«é€Ÿå¼€å§‹

### å‰ç½®è¦æ±‚

- [Bun](https://bun.sh) >= 1.0.0

### æœ¬åœ°è¿è¡Œ

1. **å®‰è£…ä¾èµ–**

```bash
bun install
```

2. **é…ç½®åº”ç”¨**

```bash
cp config.toml.example config.toml
# ç¼–è¾‘ config.toml é…ç½®ä½ çš„æä¾›å•†ä¿¡æ¯
```

3. **å¯åŠ¨æœåŠ¡**

```bash
bun run src/index.ts
```

æœåŠ¡å°†åœ¨ `http://localhost:3000` å¯åŠ¨ã€‚

## é…ç½®è¯´æ˜

é…ç½®æ–‡ä»¶ä½¿ç”¨ TOML æ ¼å¼ï¼Œä¸»è¦é…ç½®é¡¹ï¼š

```toml
[app]
host = "0.0.0.0"
port = 3000
keys = ["sk-XXXXX"]  # API å¯†é’¥åˆ—è¡¨ï¼Œç”¨äºè®¤è¯
fakeStreamInterval = 500  # fake-streaming ä¿æŒè¿æ¥é—´éš”ï¼ˆæ¯«ç§’ï¼‰

[logging]
level = "info"  # debug, info, warn, error

[providers.my-openai]
enabled = true
type = "openai"
endpoint = "https://api.openai.com/v1"
api_key = "sk-proj-1234567890"

[providers.my-openai.filter]
mode = "whitelist"  # whitelist æˆ– blacklist
models = ["gpt-4o", "gpt-4o-mini"]
```

è¯¦ç»†é…ç½®è¯´æ˜è¯·å‚è€ƒ `config.toml.example`ã€‚

## éƒ¨ç½²æ–¹å¼

### Docker éƒ¨ç½²ï¼ˆæ¨èï¼‰

#### ä½¿ç”¨ Docker Compose

```bash
# å‡†å¤‡é…ç½®æ–‡ä»¶
cp config.toml.example config.toml
# ç¼–è¾‘ config.toml

# å¯åŠ¨æœåŠ¡
docker-compose up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f

# åœæ­¢æœåŠ¡
docker-compose down
```

#### ä½¿ç”¨ Docker

```bash
# æ„å»ºé•œåƒ
docker build -t nostreaming:latest .

# è¿è¡Œå®¹å™¨
docker run -d \
  --name nostreaming \
  -p 3000:3000 \
  -v $(pwd)/config.toml:/app/config.toml:ro \
  nostreaming:latest
```

è¯¦ç»†çš„ Docker éƒ¨ç½²æŒ‡å—è¯·å‚è€ƒ [README.docker.md](./README.docker.md)ã€‚

### æœ¬åœ°éƒ¨ç½²

```bash
# å®‰è£…ä¾èµ–
bun install

# é…ç½®åº”ç”¨
cp config.toml.example config.toml
# ç¼–è¾‘ config.toml

# å¯åŠ¨æœåŠ¡
bun run src/index.ts
```

## API ä½¿ç”¨

### å¥åº·æ£€æŸ¥

```bash
curl http://localhost:3000/health
```

### è·å–æ¨¡å‹åˆ—è¡¨

```bash
curl -H "Authorization: Bearer sk-XXXXX" \
  http://localhost:3000/v1/models
```

### èŠå¤©è¡¥å…¨

```bash
curl -X POST http://localhost:3000/v1/chat/completions \
  -H "Authorization: Bearer sk-XXXXX" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "my-openai/gpt-4o",
    "messages": [
      {"role": "user", "content": "Hello!"}
    ]
  }'
```

### æµå¼è¯·æ±‚

```bash
curl -X POST http://localhost:3000/v1/chat/completions \
  -H "Authorization: Bearer sk-XXXXX" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "my-openai/gpt-4o",
    "messages": [
      {"role": "user", "content": "Hello!"}
    ],
    "stream": true
  }'
```

## æ¨¡å‹å‘½åè§„åˆ™

æ¨¡å‹åç§°æ ¼å¼ï¼š`{provider_name}/{model_id}`

ä¾‹å¦‚ï¼š

- `my-openai/gpt-4o` - ä½¿ç”¨ `my-openai` æä¾›å•†çš„ `gpt-4o` æ¨¡å‹
- `my-openai/gpt-4o-mini` - ä½¿ç”¨ `my-openai` æä¾›å•†çš„ `gpt-4o-mini` æ¨¡å‹

## æŠ€æœ¯æ ˆ

- **Runtime**: Bun
- **HTTP Framework**: Elysia
- **é…ç½®**: TOML
- **HTTP Client**: Axios
- **éªŒè¯**: Zod

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ [MIT è®¸å¯è¯](LICENSE)ã€‚
